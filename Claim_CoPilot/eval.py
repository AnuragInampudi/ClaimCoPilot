{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEdp0yTtbf3i5qobmdOTef"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"1KtAqKXaCjn-","executionInfo":{"status":"error","timestamp":1764628272488,"user_tz":300,"elapsed":9,"user":{"displayName":"Anurag Inampudi","userId":"06250032972660996083"}},"outputId":"45694619-eb06-444c-e713-1dd40bad9cdd"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name '__file__' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1571815768.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# --- Locate project root and src folder --------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mBASE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mSRC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBASE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"src\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"]}],"source":["# eval.py - Evaluation script for ClaimCopilot\n","import json\n","import random\n","import re\n","import sys\n","from pathlib import Path\n","from typing import Dict, Any, List\n","\n","# --- Locate project root and src folder --------------------------------------\n","BASE = Path(__file__).resolve().parent\n","SRC = BASE / \"src\"\n","\n","if str(SRC) not in sys.path:\n","    sys.path.append(str(SRC))\n","\n","from orchestrator import Orchestrator  # type: ignore\n","\n","DATA_DIR = BASE / \"data\"\n","OUT_DIR = BASE / \"outputs\"\n","\n","DATA_DIR.mkdir(parents=True, exist_ok=True)\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","CLAIMS_PATH = DATA_DIR / \"claims.jsonl\"\n","\n","FIELDS = [\"claimant_name\", \"policy_type\", \"claim_amount\", \"incident_date\", \"priority\"]\n","POLICY_TYPES = [\"Health\", \"Auto\", \"Property\"]\n","\n","\n","# --------------------------------------------------------------------\n","# Data loading\n","# --------------------------------------------------------------------\n","def load_claims(path: Path) -> List[Dict[str, Any]]:\n","    claims = []\n","    with path.open(\"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line:\n","                continue\n","            claims.append(json.loads(line))\n","    return claims\n","\n","\n","# --------------------------------------------------------------------\n","# Agentic pipeline wrapper\n","# --------------------------------------------------------------------\n","def run_agentic(text: str) -> Dict[str, Any]:\n","    orc = Orchestrator()\n","    state = orc.run(text)\n","    return {\n","        \"claimant_name\": state.extracted_fields.get(\"claimant_name\"),\n","        \"policy_type\": state.extracted_fields.get(\"policy_type\"),\n","        \"claim_amount\": state.extracted_fields.get(\"claim_amount\"),\n","        \"incident_date\": state.extracted_fields.get(\"incident_date\"),\n","        \"priority\": state.triage.get(\"priority\"),\n","        \"summary\": state.summary,\n","    }\n","\n","\n","# --------------------------------------------------------------------\n","# Baseline (regex + heuristics)\n","# --------------------------------------------------------------------\n","def baseline_extract_and_triage(text: str) -> Dict[str, Any]:\n","    # Amount\n","    amount = None\n","    m = re.search(r\"\\$([0-9]+(?:\\.[0-9]{2})?)\", text)\n","    if m:\n","        try:\n","            amount = float(m.group(1))\n","        except Exception:\n","            amount = None\n","\n","    # Date: YYYY-MM-DD\n","    incident_date = None\n","    m = re.search(r\"\\b(20[0-9]{2}-[01][0-9]-[0-3][0-9])\\b\", text)\n","    if m:\n","        incident_date = m.group(1)\n","\n","    # Policy type keyword\n","    policy_type = None\n","    for p in POLICY_TYPES:\n","        if p.lower() in text.lower():\n","            policy_type = p\n","            break\n","\n","    # Very simple “Firstname Lastname submitted/filed”\n","    claimant_name = None\n","    m = re.search(r\"([A-Z][a-z]+ [A-Z][a-z]+)\\s+(submitted|filed|presents)\", text)\n","    if m:\n","        claimant_name = m.group(1)\n","\n","    # Priority heuristic\n","    t_lower = text.lower()\n","    if \"fracture\" in t_lower or \"surgery\" in t_lower or \"hospital\" in t_lower:\n","        priority = \"High\"\n","    elif amount is not None and amount >= 3000:\n","        priority = \"Medium\"\n","    else:\n","        priority = \"Low\"\n","\n","    return {\n","        \"claimant_name\": claimant_name,\n","        \"policy_type\": policy_type,\n","        \"claim_amount\": amount,\n","        \"incident_date\": incident_date,\n","        \"priority\": priority,\n","    }\n","\n","\n","# --------------------------------------------------------------------\n","# Metrics helpers\n","# --------------------------------------------------------------------\n","def update_prf_counts(gold, pred, bucket: Dict[str, int]) -> None:\n","    if gold is None and pred is None:\n","        return\n","    if pred == gold:\n","        bucket[\"tp\"] += 1\n","    else:\n","        if pred is not None:\n","            bucket[\"fp\"] += 1\n","        if gold is not None:\n","            bucket[\"fn\"] += 1\n","\n","\n","def prf(tp: int, fp: int, fn: int):\n","    prec = 0.0 if (tp + fp) == 0 else tp / (tp + fp)\n","    rec = 0.0 if (tp + fn) == 0 else tp / (tp + fn)\n","    if prec + rec == 0:\n","        f1 = 0.0\n","    else:\n","        f1 = 2 * prec * rec / (prec + rec)\n","    return prec, rec, f1\n","\n","\n","# --------------------------------------------------------------------\n","# Main evaluation\n","# --------------------------------------------------------------------\n","def main(eval_n: int = 300, seed: int = 123):\n","    print(f\"Loading claims from: {CLAIMS_PATH}\")\n","    claims = load_claims(CLAIMS_PATH)\n","    print(f\"Total claims available: {len(claims)}\")\n","\n","    random.seed(seed)\n","    sampled_claims = random.sample(claims, min(eval_n, len(claims)))\n","    print(f\"Evaluating on a sampled subset of {len(sampled_claims)} claims.\\n\")\n","\n","    metrics = {\n","        \"agentic\": {f: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for f in FIELDS},\n","        \"baseline\": {f: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for f in FIELDS},\n","    }\n","\n","    case_studies = []\n","\n","    for rec in sampled_claims:\n","        text = rec[\"text\"]\n","        gold = rec\n","\n","        agentic = run_agentic(text)\n","        baseline = baseline_extract_and_triage(text)\n","\n","        case_studies.append(\n","            {\n","                \"id\": rec[\"id\"],\n","                \"text\": text,\n","                \"gold\": {f: gold[f] for f in FIELDS},\n","                \"agentic_pred\": {f: agentic[f] for f in FIELDS},\n","                \"baseline_pred\": {f: baseline[f] for f in FIELDS},\n","            }\n","        )\n","\n","        for field in FIELDS:\n","            g_val = gold[field]\n","            update_prf_counts(g_val, agentic[field], metrics[\"agentic\"][field])\n","            update_prf_counts(g_val, baseline[field], metrics[\"baseline\"][field])\n","\n","    # Summarize metrics\n","    summary_table = {}\n","    print(\"=== Extraction + Triage: Precision / Recall / F1 ===\")\n","    for field in FIELDS:\n","        ag_m = metrics[\"agentic\"][field]\n","        bl_m = metrics[\"baseline\"][field]\n","\n","        ag_p, ag_r, ag_f1 = prf(ag_m[\"tp\"], ag_m[\"fp\"], ag_m[\"fn\"])\n","        bl_p, bl_r, bl_f1 = prf(bl_m[\"tp\"], bl_m[\"fp\"], bl_m[\"fn\"])\n","\n","        summary_table[field] = {\n","            \"agentic_precision\": ag_p,\n","            \"agentic_recall\": ag_r,\n","            \"agentic_f1\": ag_f1,\n","            \"baseline_precision\": bl_p,\n","            \"baseline_recall\": bl_r,\n","            \"baseline_f1\": bl_f1,\n","            \"agentic_counts\": ag_m,\n","            \"baseline_counts\": bl_m,\n","        }\n","\n","        print(\n","            f\"{field:15s} | Agentic P/R/F1: {ag_p:.2f}/{ag_r:.2f}/{ag_f1:.2f} \"\n","            f\"| Baseline P/R/F1: {bl_p:.2f}/{bl_r:.2f}/{bl_f1:.2f}\"\n","        )\n","\n","    # Save results\n","    eval_out_path = OUT_DIR / \"eval_results.json\"\n","    with eval_out_path.open(\"w\", encoding=\"utf-8\") as f:\n","        json.dump({\"summary\": summary_table, \"metrics_raw\": metrics}, f, indent=2)\n","\n","    cases_out_path = OUT_DIR / \"case_studies.jsonl\"\n","    with cases_out_path.open(\"w\", encoding=\"utf-8\") as f:\n","        for cs in case_studies:\n","            f.write(json.dumps(cs) + \"\\n\")\n","\n","    print(\"\\nSaved eval results to:\", eval_out_path.resolve())\n","    print(\"Saved case studies to :\", cases_out_path.resolve())\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}